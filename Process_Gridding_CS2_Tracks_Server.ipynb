{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2486a044-09a3-48c1-bfc7-aaecbbe3dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "from numpy import transpose as T\n",
    "from numpy import genfromtxt as gftxt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "# # # #\n",
    "# Define the custom Lambert Azimuthal Equal Area projection\n",
    "map_projection = ccrs.LambertAzimuthalEqualArea(central_longitude=-105,central_latitude=74)\n",
    "\n",
    "# Coordinates to transform (lon, lat) in the Plate Carree projection\n",
    "geo_extent = [-140, -70, 64, 79]\n",
    "\n",
    "def transform_coords(lon, lat, projection):\n",
    "    x, y = projection.transform_point(lon, lat, ccrs.PlateCarree())\n",
    "    return x, y\n",
    "\n",
    "corners = [\n",
    "    (geo_extent[0], geo_extent[2]),  # SW corner\n",
    "    (geo_extent[1], geo_extent[2]),  # SE corner\n",
    "    (geo_extent[0], geo_extent[3]),  # NW corner\n",
    "    (geo_extent[1], geo_extent[3])   # NE corner\n",
    "]\n",
    "\n",
    "# Transform coordinates to the desired map area\n",
    "proj_corners = [transform_coords(lon, lat, map_projection) for lon, lat in corners]\n",
    "x_coords, y_coords = zip(*proj_corners)\n",
    "\n",
    "x_min, x_max = min(x_coords), max(x_coords)\n",
    "y_min, y_max = min(y_coords), max(y_coords)\n",
    "\n",
    "grid_spacing = 25000 # 25 km\n",
    "\n",
    "x_grid_centre = np.arange(x_min-grid_spacing/2,x_max + grid_spacing, grid_spacing)\n",
    "y_grid_centre = np.arange(y_min-grid_spacing/2,y_max + grid_spacing, grid_spacing)\n",
    "new_x_centre, new_y_centre = np.meshgrid(x_grid_centre, y_grid_centre)\n",
    "\n",
    "x_grid_edge = np.arange(x_min,x_max + grid_spacing, grid_spacing)\n",
    "y_grid_edge = np.arange(y_min,y_max + grid_spacing, grid_spacing)\n",
    "new_x_edge, new_y_edge= np.meshgrid(x_grid_edge, y_grid_edge)\n",
    "\n",
    "print('Edges grid shape = ',np.shape(new_x_edge))\n",
    "print('Centre grid shape = ',np.shape(new_x_centre))\n",
    "\n",
    "\n",
    "# # # # \n",
    "# Griding Files\n",
    "# Navigate to CS2 Files\n",
    "\n",
    "grid_output_folder = ('/home/amyswiggs/Chapter2/NWP_CS2_Grids_Cartopy/')\n",
    "\n",
    "#years = ['2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022']\n",
    "years = ['2023']\n",
    "months = ['01','02','03','04','05','09','10','11','12']\n",
    "#years = ['2010']\n",
    "#months = ['10','11','12']\n",
    "\n",
    "# Loop through years and months\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        \n",
    "        CS2_files = sorted(glob.glob('/cpdata/SATS/RA/CRY/processed/arco/'+str(year)+str(month)+'_MERGE/*.elev'))\n",
    "        \n",
    "        lons,lats,types,peakiness,iceconc,ssd =[],[],[],[],[],[]\n",
    "        \n",
    "        # Loop through files\n",
    "        for file in CS2_files:\n",
    "            try:\n",
    "                print(file)\n",
    "                data = T(gftxt((file)))\n",
    "\n",
    "                lon = data[6]\n",
    "                lat = data[5]\n",
    "                typ = data[0]\n",
    "                icep = data[11]\n",
    "\n",
    "                lons.extend(lon)\n",
    "                lats.extend(lat)\n",
    "                types.extend(typ)\n",
    "                iceconc.extend(icep)\n",
    "\n",
    "                ice_conc = np.array(iceconc)\n",
    "                conc_0 = np.where(ice_conc < 0, np.nan, ice_conc)\n",
    "\n",
    "                mask = np.isnan(conc_0)\n",
    "\n",
    "                types_0 = np.where(mask, np.nan, types)\n",
    "\n",
    "                ocean_val = 1\n",
    "                ocean_values = np.where(types_0 == ocean_val, 1,0)\n",
    "\n",
    "                floe_val = 3\n",
    "                floe_values = np.where(types_0 == floe_val,1,0)\n",
    "\n",
    "                lead_val = 2\n",
    "                lead_values = np.where(types_0 == lead_val,1,0)\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing {file}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "        lons_array = np.array(lons)\n",
    "        lats_array = np.array(lats)\n",
    "        \n",
    "        # Grid the data \n",
    "        x, y = map_projection.transform_points(ccrs.PlateCarree(), lons_array, lats_array)[:, :2].T\n",
    "        \n",
    "        # Set minimum count, and count the number of values\n",
    "        min_scipy_count = T(scipy.stats.binned_statistic_2d(x,y,types_0,bins=(x_grid_edge,y_grid_edge),statistic='count')[0])\n",
    "\n",
    "        #\n",
    "        count_ocean=T(scipy.stats.binned_statistic_2d(x,y,ocean_values,bins=(x_grid_edge,y_grid_edge),statistic='sum')[0])\n",
    "        count_min_ocean = np.where(min_scipy_count > 50, count_ocean,np.nan)\n",
    "        np.save(grid_output_folder+str(year)+str(month)+'_CountOceanRegrid.npy',count_min_ocean)\n",
    "        \n",
    "        #\n",
    "        count_floes=T(scipy.stats.binned_statistic_2d(x,y,floe_values,bins=(x_grid_edge,y_grid_edge),statistic='sum')[0])\n",
    "        count_min_floes = np.where(min_scipy_count > 50, count_floes,np.nan)\n",
    "        np.save(grid_output_folder+str(year)+str(month)+'_CountFloesRegrid.npy',count_min_floes)\n",
    "        \n",
    "        #\n",
    "        count_leads=T(scipy.stats.binned_statistic_2d(x,y,lead_values,bins=(x_grid_edge,y_grid_edge),statistic='sum')[0])\n",
    "        count_min_leads = np.where(min_scipy_count > 50, count_leads,np.nan)\n",
    "        np.save(grid_output_folder+str(year)+str(month)+'_CountLeadsRegrid.npy',count_min_leads)\n",
    "        \n",
    "        # \n",
    "        conc0_binned = T(scipy.stats.binned_statistic_2d(x,y,conc_0,bins=(x_grid_edge,y_grid_edge),statistic=np.nanmean)[0])\n",
    "        conc0_min_binned = np.where(min_scipy_count > 50, conc0_binned,np.nan)\n",
    "        np.save(grid_output_folder+str(year)+str(month)+'_ConcentrationRegrid.npy',conc0_min_binned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
