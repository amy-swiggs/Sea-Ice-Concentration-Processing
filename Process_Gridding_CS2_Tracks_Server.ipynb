{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2486a044-09a3-48c1-bfc7-aaecbbe3dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "from numpy import transpose as T\n",
    "from numpy import genfromtxt as gftxt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "# # # #\n",
    "# Setting up map projection\n",
    "map_projection = ccrs.LambertAzimuthalEqualArea(central_longitude=-105,central_latitude=74)\n",
    "\n",
    "# Bin Edges for GRIDDING data (e.g., CS2)\n",
    "fig1 = plt.figure(figsize=(15,20))\n",
    "\n",
    "ax1 = plt.axes(projection=map_projection) # This sets the projection of the data\n",
    "ax1.set_extent([-145, -55, 66, 79], crs=ccrs.PlateCarree())\n",
    "ax1.coastlines(linewidth=0.2)\n",
    "\n",
    "# Get axis limits for restricting grid\n",
    "x_min, x_max, y_min, y_max = ax1.get_extent()\n",
    "\n",
    "print(\"X-axis limits:\", x_min, x_max)\n",
    "print(\"Y-axis limits:\", y_min, y_max)\n",
    "\n",
    "# Grid spacing is 25km\n",
    "grid_spacing = 25000\n",
    "# Get bin edges\n",
    "bin_edges=np.arange(x_min,x_max+grid_spacing,grid_spacing)\n",
    "new_x_edge, new_y_edge = np.meshgrid(bin_edges, bin_edges)\n",
    "\n",
    "print('Edges Grid Shape', np.shape(bin_edges))\n",
    "\n",
    "# # # # \n",
    "# Griding Files\n",
    "# Navigate to CS2 Files\n",
    "\n",
    "grid_output_folder = ('/home/amyswiggs/Chapter2/NWP_CS2_Grids_Cartopy/')\n",
    "\n",
    "years = ['2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022']\n",
    "months = ['01','02','03','04','05','09','10','11','12']\n",
    "\n",
    "# Loop through years and months\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        \n",
    "        CS2_files = sorted(glob.glob('/cpdata/SATS/RA/CRY/processed/arco/'+str(year)+str(month)+'_MERGE/*.elev'))\n",
    "        \n",
    "        lons,lats,types,peakiness,iceconc,ssd =[],[],[],[],[],[]\n",
    "        \n",
    "        # Loop through files\n",
    "        for file in CS2_files:\n",
    "            try:\n",
    "                print(file)\n",
    "                data = T(gftxt((file)))\n",
    "\n",
    "                lon = data[6]\n",
    "                lat = data[5]\n",
    "                typ = data[0]\n",
    "                icep = data[11]\n",
    "\n",
    "                lons.extend(lon)\n",
    "                lats.extend(lat)\n",
    "                types.extend(typ)\n",
    "                iceconc.extend(icep)\n",
    "\n",
    "                ice_conc = np.array(iceconc)\n",
    "                conc_0 = np.where(ice_conc < 0, np.nan, ice_conc)\n",
    "\n",
    "                mask = np.isnan(conc_0)\n",
    "\n",
    "                types_0 = np.where(mask, np.nan, types)\n",
    "\n",
    "                ocean_val = 1\n",
    "                ocean_values = np.where(types_0 == ocean_val, 1,0)\n",
    "\n",
    "                floe_val = 3\n",
    "                floe_values = np.where(types_0 == floe_val,1,0)\n",
    "\n",
    "                lead_val = 2\n",
    "                lead_values = np.where(types_0 == lead_val,1,0)\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing {file}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "        lons_array = np.array(lons)\n",
    "        lats_array = np.array(lats)\n",
    "        \n",
    "        # Grid the data \n",
    "        x, y = map_projection.transform_points(ccrs.PlateCarree(), lons_array, lats_array)[:, :2].T\n",
    "        \n",
    "        # Set minimum count, and count the number of values\n",
    "        min_scipy_count = T(scipy.stats.binned_statistic_2d(x,y,types_0,bins=bin_edges,statistic='count')[0])\n",
    "\n",
    "        #\n",
    "        count_ocean=T(scipy.stats.binned_statistic_2d(x,y,ocean_values,bins=bin_edges,statistic='sum')[0])\n",
    "        count_min_ocean = np.where(min_scipy_count > 50, count_ocean,np.nan)\n",
    "        np.save(grid_output_folder+str(year)+str(month)+'_CountOcean.npy',count_min_ocean)\n",
    "        \n",
    "        #\n",
    "        count_floes=T(scipy.stats.binned_statistic_2d(x,y,floe_values,bins=bin_edges,statistic='sum')[0])\n",
    "        count_min_floes = np.where(min_scipy_count > 50, count_floes,np.nan)\n",
    "        np.save(grid_output_folder+str(year)+str(month)+'_CountFloes.npy',count_min_floes)\n",
    "        \n",
    "        #\n",
    "        count_leads=T(scipy.stats.binned_statistic_2d(x,y,lead_values,bins=bin_edges,statistic='sum')[0])\n",
    "        count_min_leads = np.where(min_scipy_count > 50, count_leads,np.nan)\n",
    "        np.save(grid_output_folder+str(year)+str(month)+'_CountLeads.npy',count_min_leads)\n",
    "        \n",
    "        # \n",
    "        conc0_binned = T(scipy.stats.binned_statistic_2d(x,y,conc_0,bins=bin_edges,statistic=np.nanmean)[0])\n",
    "        conc0_min_binned = np.where(min_scipy_count > 50, conc0_binned,np.nan)\n",
    "        np.save(grid_output_folder+str(year)+str(month)+'_Concentration.npy',conc0_min_binned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
